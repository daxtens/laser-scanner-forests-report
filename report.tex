% todo - point out that map is nto built on real loop closures; cannot
% backtrack or update, etc (see huang p3)
%\todo{Some form of introduction: reference previous post-processing
%  work, explain that this now provides that in real time.}
%% - do we even have a reference for this???


%%
%% Template thesis.tex
%%
\documentclass[12pt,oneside,a4paper]{book}
%\usepackage[palatino]{anuthesis}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage[left=3cm,top=2cm,bottom=2cm,right=2cm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{gensymb}
\usepackage{thesis}
\usepackage{cite,url,citesort}
\usepackage{caption}
\usepackage[lined,boxed]{algorithm2e}
\usepackage{enumerate}
%\usepackage{epstopdf}
%\usepackage{epsfig}
%\usepackage{makeidx}
%\usepackage{acmnew-xref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Preamble
\title{Investigating the feasibility of laser scanners for autonomous
  navigation of hexacopters in forests}
\author{Daniel Axtens}
\date{\today}

\renewcommand{\thepage}{\roman{page}}

%\makeindex
\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Title page
\pagestyle{empty}
\thispagestyle{empty}

\begin{titlepage}
  \enlargethispage{2cm}
  \begin{center}
    \makeatletter
    \Huge\textbf{\@title} \\[2.9cm]
    %\Huge\textbf{\thesisqualifier} \\[2.5cm]
    \huge\textbf{\@author} \\[10.5cm]
    \makeatother
    \LARGE ENGN4718\\
    Supervisor: Dr Jon Kim\\[2cm]
    2014
  \end{center}
\end{titlepage}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Here begin the preliminaries
%\input frontmatter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Dedication (optional)
%\cleardoublepage
%\pagestyle{empty}
%\input dedication

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Acknowledgements (optional!)
%\cleardoublepage
%\pagestyle{empty}
%\input ack

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Abstract
\cleardoublepage
\pagestyle{headings}
%\input{abstract}
Abstract!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Table of contents
\cleardoublepage
\pagestyle{headings}
\markboth{Contents}{Contents}
\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Here begins the main text
\mainmatter

\chapter{Aims and Contribution}
\label{cha:aims}

%It is often difficult to determine exactly what in the report is the student's 
%own work, what is new and what the actual aims and outcomes were. Each 
%report is required to have a section that specifically sets out what the goals 
%and outcomes of the project were. For example, did you undertake:
%- a research project that contributed new knowledge;
%- a simulation project that required you to replicate relatively 
%complicated, but previously published (by someone else) results;
%- a design project which took into account skills learned during your 
%degree – or new skills you had to acquire;
%- a build project based on someone else’s design (e.g., your 
%supervisor or an otherwise published design), but requiring the 
%application, and possibly learning, of some analytical skills.
%This section should then detail the outcome (e.g. what was the research 
%contribution or what were the new skills learned to build the widget) 
%explicitly stating what your contribution was. 

\textbf{This is a research project with strong design and build elements.}

This project set out to achieve the ambitious goal of hovering a
hexacopter in a fixed position, outdoors, using a laser scanner with
polar scan matching to provide position information. During the course
of the project, it was determined that unaided polar scan matching
would not be sufficient, due to the drift inherent in the
technique. Therefore, the project explored how the position can be
corrected by detecting trees, and using their fixed positions. I wrote
new code to explore this, and concluded that is possible, and indeed
feasible in real time. As a result of this new direction, hovering
control was not attempted.

The goal can therefore be summarised as providing an answer to the
following question:
\begin{quote}
  \textbf{Are laser scanners feasible for autonomous navigation of
    hexacopters in forests?}
\end{quote}

The outcomes of this project can be summarised in terms of the
\textbf{hardware} designed and built, the \textbf{software} written,
and the \textbf{knowledge} gained towards answering the main
question. In addition, the project assisted in \textbf{skill
  development}.

\section{Hardware}
\label{sec:hardware-1}

The project required \emph{designing and building} a
gimbal-stabilised, vibration-damped mount for a laser scanner, and
mounting it on landing gear for a hexacopter.

The major parts --- gimbal, anti-vibration mount, onboard computer, laser
scanner, hexacopter and landing gear --- were supplied, but they needed
to be put together, both mechanically and electrically.

The outcome of this part is a working payload with those parts
mounted, that has been tested and is known to work. This required both
physical hardware development, and electrical work. All the designs
are original. Fabrication of the parts from my designs was done on a
laser cutter by Alex Martin.

During flight tests, the hexacopter was flown by Jon Kim.

\section{Software}
\label{sec:software-1}

The project required significant development within the ROS
environment. Chapter~\ref{sec:software} details which software
components were new to this project, but in summary, I:
\begin{itemize}
\item Undertook significant work updating, debugging and adapting the
  Polar Scan Matcher node. This node was written before the project,
  but required significant work throughout the course of the
  project. This node is written in C++.
\item Wrote completely new nodes in Python to detect trees and
  determine the position of the hexacopter based on the tree
  positions.
\end{itemize}

The software is designed to be reusable in future projects, so the
software itself is an outcome.

\section{Knowledge}
\label{sec:knowledge}

Together, the software and hardware aimed to provide the tools
necessary answer the original question: are laser scanners feasible
for autonomous navigation of hexacopters in forests?

The project contributes to answering this question, by testing the
hardware and software developed in real unstructured environments. The
results provide evidence that laser scanner navigation is indeed
feasible. The project also provide suggestions for further
implementation work and for future research.

\section{Skill Development}
\label{sec:skill-development}

The following new skills were developed during this project.

\begin{itemize}
\item SolidWorks, for design of physical components.
\item Arduino programming, for the gimbal.
\item Flying skills
\item Familiarity with the ROS (Robot Operating System) environment.
 \end{itemize}
 
The following existing were used/developed:
\begin{itemize}
\item Basic electronics and soldering skills
\item Basic hardware skills
\item C++ programming
\item Python programming
\end{itemize}

\section{Reproducible Research}
\label{sec:repr-rese}

Reproducibility is a core requirement of scientific research. Results
can only be trusted if they can be replicated by others. In addition
to increasing transparency and confidence in the scientific process,
reproducibility accelerates scientific progress by making it easier to
verify, continue and extend prior work.

Traditionally, reproducibility was accomplished by publishing papers
that clearly and concisely explained the work done. However, with the
enormous complexity of many projects, it is impossible to include the
complete details within a report of reasonable length. Fortunately,
the internet makes it easy to provide not just all the details, but
all the code and all the data. Full reproducibility --- at least of
software elements --- should be a key goal.

As such, this report, the code written for it, and the data sets
analysed, have been made freely available online. They can be accessed
at \url{https://github.com/daxtens/laser-scanner-forests-report}.
While their application is more limited, all the relevant CAD files
have also been uploaded to the same place.

\todo{verify that all code and data are there}


\chapter{Introduction}
\label{cha:intro}

\chapter{Background}
\label{cha:background}

\todo{Points from \cite{achtelik2009stereo} --- or in introduction.}

Definitions:
\begin{itemize}
\item Localization
\item SLAM
\item Quadrotor/hexacopter dynamics, challenges as compared to ground robots.
\end{itemize}


\section{Literature Survey}
\label{sec:litsurvey}

There is a significant body of work on GPS-denied indoor areas.

One approach is to use a single camera, and use computer vision
techniques such as object detection and optical flow. This is the
approach taken by \cite{5152680}, and requires significant image
processing. In this case the processing, while successful, is
specialised to indoor environments.

A popular and more flexible approach in recent years has been to use
commercial stereoscopic or depth sensing cameras. For example,
\cite{huang2011visual} uses the Microsoft Kinect to navigate
autonomously indoors.

The Kinect provides an RGB colour image and a depth map generated by
an IR projector and a monochrome camera. Of particular relevance to
this project, the use of an IR projector limits its range. It's
unclear if this would severely compromise its performance outdoors,
where obstacles are often much further away.

The images from the Kinect are processed on board for basic
localisation, and also sent to a separate, more powerful computer,
which performs full SLAM, transmits corrections back to the on-board
processor, and builds a dense 3D map.

Of particular relevance to this project is \cite{achtelik2009stereo}. The authors
constructed 2 quadcopters - one that used the a laser scanner, and one
that used a custom stereoscopic camera. (More detail on the laser
based operation is given in the companion paper
\cite{Bachrach09autonomousflight}.) 

The paper compares the performance of both the laser scanner
approach and the camera approach by using a VICON system to provide a
`ground truth'. This approach provides for informative data, but is
unsuitable for use outside.

The paper details the considerable amount of effort required to have
the stereoscopic image processing happen in real-time. The quadrotor
itself was equipped with a 1.6GHz onboard computer, which used WiFi to
offload image processing to a 2.4GHz Core2 Duo laptop. The laser
scanner data, on the other hand, was processed onboard on a Gumstix
board --- highlighting the computational disparity between the two
approaches.

%\todo{talk about their scan matching algo?}

The team successfully ran autonomous flight trials and concluded that
both approaches were feasible, and had their own strengths and
weaknesses.

%\begin{itemize}
%\item Considers both stereo vision and laser
%\item uses same laser scanner, also with downward facing points
%\item Gumstix controller.
%\item Indoor only!
%\item Good set of challenges - consider them in background!
%\item SLAM is only 0.3Hz; ours is 4-5Hz
%\item Their laser scan matching is based on Olsen - completely
 % different
%\item lots of special work needed to do processing of visual fast enough.
%\item Compares results to VICON for ground truth --- link to Jon's
 % paper
%\item Doesn't use ROS.
%\end{itemize}



The problem of navigation in forests is considered in
\cite{langelaan2005towards}. Here the authors developed a SLAM
algorithm based on an IMU and a monocular camera. The monocular camera
is lightweight, but can only provide bearings to obstacles, not
distances, complicating processing.

The test bed used was a remote controlled car, rather than a copter:
the focus being on testing the algorithm. The processing for the
algorithm was done entirely from a remote computer; none was done
on-board. Furthermore, the obstacles used were artificial: red
``blobs'' mounted on poles. This vastly simplified the vision
processing (especially compared to \cite{5152680}) but this would need
to be addressed before the approach was feasible in real
environments. In addition, some \emph{a priori}
knowledge was given to the robot.

The main contribution of this paper is the comparison of a regular
Kalman filter with an unscented Kalman filter. 
 
\subsection{Where does this work fit into the literature?}
\label{sec:where-does-this}

This project is quite novel in the following areas:
\begin{itemize}
\item Heavy emphasis on outdoor navigation in real environments.
\item Algorithm selection and coding for real-time, on-board
  operation, without the requirement of an `base station' computer to
  do heavy processing.
\end{itemize}

It is most similar to \cite{achtelik2009stereo} (with respect to laser
scanners), except outdoors instead of indoors. Therefore, the
additional challenges of vastly sparser scans in outdoor environments
are addressed.

\section{Polar Scan Matching}
\label{sec:polar-scan-matching}

As a key requirement of the project is to make efficient use of
limited computational power, polar scan matching (PSM) was chosen as the
primary method of scan matching, over other more well known methods
such as Iterated Closest Point.

PSM is defined in \cite{polarscanmatching}. The key idea of PSM is to
take advantage of the polar structure of laser scans to increase
efficiency. 

The efficiency gain is quite significant. A naive implementation of
ICP has complexity $O(n^2)$ in the number of points. If the search
angles are constrained, this can be reduced to $O(kn)$, where $k$ is
proportion to the angular resolution. Alternatively, with the
use of appropriate data structures, the time can be reduced to
$O(n\log n)$. PSM, on the other hand, has complexity of $O(n)$.

The downside of PSM is that it can only match a scan with the
immediately preceding scan. It has no ability to store multiple
previous scans, meaning it has no ability to keep fixed points
constant over time. As such, errors accumulate that cause PSM to
`drift' with respect to the ground truth over time.

Determining the qualitative extent of this drift, and correcting for
it, is thus a focus of this report.

\chapter{Construction: Hardware}
\label{sec:hardware}

\section{Laser Scanner and Gimbal}
\label{sec:laser-scanner-gimbal}

The hardware was built in two phases - Mk I around a Hokuyo
UBG-04LX-F01
scanner,\footnote{\url{http://www.hokuyo-aut.jp/02sensor/07scanner/download/pdf/UBG-04LX-F01_spec1.pdf}}
and Mk II around a Hokuyo UTM-30LX scanner.\footnote{\url{http://www.hokuyo-aut.jp/02sensor/07scanner/download/pdf/UTM-30LX_spec_en.pdf}}


\subsection{Mk I}
\label{sec:mk-i}

Initially, the assembly was built around a UBG-04LX-F01 laser
scanner.

The UBG-04LX-F01:
\begin{itemize}
\item Has a $240\degree$ scanning range.
\item Produces scans of 682 points, each separated by $0.36\degree$.
\item Has a maximum range of 4000mm.
\item Draws 12V.
\item Provides both serial and USB output.
\item Produces 40 complete scans per second.
\end{itemize}

The scanner was fit into a X-CAM X140B gimbal set.\footnote{\url{http://www.x-camtech.com/Downloads/X-CAM_X140B_User_Manual.pdf}}

The X140B:
\begin{itemize}
\item Is a 2-axis brushless gimbal.
\item Is designed to fit Sony NEX5 series cameras.
\item Draws 12V.
\end{itemize}

After removing one of the supports designed for the Sony NEX5 cameras,
the scanner fit neatly into the gimbal and was secured on a temporary
basis with velcro and foam.

However, as the scanner provides only a USB socket, rather than a USB
cable, it had to be positioned so as to provide access to the USB port
through a hole in the top panel of the gimbal. This necessitated
placing the scanner on one side of the gimbal, and quite far forward,
as shown in Figure~\ref{fig:mk1-mount}. To counterbalance this, a
U-bolt was placed on the other side of the gimbal and loaded with nuts
to roughly balance the platform.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.5\textwidth]{figs/mk1-mount}
  \caption{Picture of the Mk I, showing the laser scanner mounted with the USB port accessible. This is before the installation of the U-bolt.}
  \label{fig:mk1-mount}
\end{figure}

While this was sufficient to allow testing of the software and mount,
it was excessively heavy and degraded gimbal performance. Designing a
replacement platform was identified as a priority for later stages of the project.

\subsection{Mk I Mod II}
\label{sec:mk-ib}

During development, power was accidentally connected backwards across
the gimbal, blowing an IC on the control board. Unhelpfully, the
identifying marks on the ICs were ground off before the gimbal was
shipped, so it was impossible to replace the damaged IC. Instead, the
entire gimbal control system had to be replaced.

The gimbal control board was replaced with a Martinez
V3.\footnote{\url{http://brushlessgimbal.de/}, and see also \url{http://www.hobbyking.com/hobbyking/store/__41386__2_Axis_Brushless_Camera_Gimbal_Stabilization_Control_Board_w_IMU.html}}

The mounting holes in the new board did not fit the existing
mounts for the old board, requiring an adaptor board, shown below in
Figure~\ref{fig:gmb}. The large holes (M3) mount the new board on
nylon spacers, with the small holes (M2) attaching to gimbal.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.4\textwidth]{figs/gmb}
  \caption{SolidWorks render of the gimbal mating board. The
    SolidWorks file and DXF export are available on the project repository.}
  \label{fig:gmb}
\end{figure}

This was initially laser cut out of 3mm MDF,
however this proved too thick: the original mounting screws were too
short to go through the board and in to the mounts below. A 2mm thick board
proved much more successful.
 
Replacing the board also necessitated removing the IMU supplied with
the gimbal originally and installing a new one. The new IMU
fortunately fit in the space taken up by the old gimbal, and was
hot-glued in place.

Unlike the old board, this board does not come pre-programmed. The
board runs an Arduino, and the controller software is open-source and
available online.\footnote{\url{http://sourceforge.net/projects/brushless-gimbal-brugi/}} The software was installed and
tuned. It performed poorly with the heavy Mk I arrangement, but fixing
this was postponed due to the upcoming Mk II.

\subsection{Mk II}
\label{sec:mk-ii}

As explained in Section~\ref{sec:psm-outdoor}, it was decided to
replace the laser scanner to improve range and thus hopefully improver
performance outdoors.

The replacement laser scanner was a Hokuyo UTM-30LX scanner. 

The UTM-30LX:
\begin{itemize}
\item Has a $270\degree$ scanning range.
\item Produces scans of 1080 points, each separated by $0.25\degree$.
\item Has a maximum range of 30m.
\item Draws 12V, between 0.7A and 1A.
\item Provides both serial and USB output.
\item Produces 1 scan every 25ms (40 scans per second).
\item Minimum detectable width at 10m: 130mm.
\end{itemize}

However, this scanner is too tall to fit neatly into the gimbal
mount. As such, the top plate and base plate were removed and a new
gimbal base plate was designed in SolidWorks. The plate is pictured in
Figure~\ref{fig:baseplate}. The board is designed with 3 sets of
holes, because it was unclear where the laser scanner would need to be
placed to balance the gimbal.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\textwidth]{figs/baseplate}
  \caption{The gimbal base plate as rendered in SolidWorks. The SolidWorks part and DXF export are available from the project repository.}
  \label{fig:baseplate}
\end{figure}

Only one base plate was fabricated, being laser cut out of 3mm
MDF. After fabrication, the following mistakes were discovered, which
should be corrected should another base plate be fabricated in future:
\begin{itemize}
\item The holes for mounting the rest of the gimbal were designed as
  M2, where as in fact they are M3. (The holes were manually enlarged
  for the sake of expediency.) Version 2 of the board should enlarge
  the holes before laser cutting.
\item Enlarging the holes also requires extending the board so that
  there's enough material on either side of the hole to support the
  weight. (The present board is cutting it perilously close.)
\end{itemize}

The following optimisations could also be made:
\begin{itemize}
\item The existing board has two cut-outs on either side of the
  scanner that were put there for the height sensor. These are
  unnecessary, and should be replaced with a more comprehensive
  weight-reduction strategy.
\item Only the middle set of holes are required. This will allow the
  board to be simplified and reduced in size.
\end{itemize}

Having fabricated the base plate, the gimbal was
re-adjusted. Performance was \emph{considerably} better than with the
Mk I.
\newpage
\section{Onboard computer}
\label{sec:onboard-computer}

A Pico-ITX form-factor single-board computer was installed to process
the scanner data in real time. 

The board is a LP-170C Pico-ITX:\footnote{\url{http://www.commell.com.tw/Download/Datasheet/LP-170_Datasheet.pdf}}
\begin{itemize}
\item 1.8GHz Atom processor
\item 4GB memory installed
\item 4xUSB2 port
\item Compact Flash card for main storage (24GB installed)
\item Draws 12V.
\end{itemize}

The operating system and software set up on the computer is detailed
in the Software chapter below.
\newpage
\section{Power supply}
\label{sec:power-supply-cons}

The three powered components (gimbal, scanner and PC) all require 12V
power. However, the hexacopter uses 4 cell LiPo batteries, which
provide 14.8V. As such, a buck converter is used to down-convert the
voltage. The convert is shown in
Figure~\ref{fig:converter} below.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.2\textwidth]{figs/converter}
  \caption{One of the switching converters}
  \label{fig:converter}
\end{figure}

The converters are rated at 25W. At 12V, this is $\approx 2$A. As
such, it was necessary to split the loads between two converters. One
converter powers the PC and the scanner, and the other powers the
gimbal. A block diagram is shown in Figure~\ref{fig:power} (the
battery, regulator and load all share a common ground).

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.5\textwidth]{figs/power}
  \caption{Block diagram of the power system}
  \label{fig:power}
\end{figure}

In addition, a locking connector was installed onto the gimbal
controller board instead of the original two pin connector. (In
addition, the connector can only be inserted one way, eliminating the
risk of destroying another board.)

\section{Height measurement setup}
\label{sec:height-meas-setup}

It is desirable for the laser scanner to also be able to provide
information on the altitude of the hexacopter. To this end, a
downwards facing mirror is required, to reflect the last few degrees
of the scan down.

It was desirable for the mirror assembly to be adjustable after
fabrication. As such it was designed so the mirror was held in by two
circular rings, which could be rotated through a mount.

This was modelled in SolidWorks as shown in
Figure~\ref{fig:mirror-solidworks}. The completed mirror assembly is shown below in
Figure~\ref{fig:mirror}.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.45\textwidth]{figs/mirror}
  \caption{The completed mirror assembly.}
  \label{fig:mirror}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.7\textwidth]{figs/mirrorassembly}\\
  ~\\
  \includegraphics[width=0.4\textwidth]{figs/mirrorholder}
  \includegraphics[width=0.4\textwidth]{figs/mirrorholdermount}
  \caption{The system model (top), the individual rings (bottom left) and the piece holding the rings (bottom right). The SolidWorks parts and DXF exports are available from the project repository.}
  \label{fig:mirror-solidworks}
\end{figure}

The mirror is a front-faced mirror---silver deposited on silicon---in
order to prevent error from refraction caused by having glass in front
of the reflective surface.

When the mirror was installed, it was discovered that it was too high,
and the entire assembly had to be tilted down and held in place with
hot glue. This assembly mounts on the top of the support - future
assemblies should mount on the bottom side of the top of the support,
with screws going upwards into the support, rather than downwards.

\newpage
\section{Attaching to hexacopter landing gear}
\label{sec:attach-hexac-land}

The gimbal was mounted to an anti-vibration mount with cable
ties. The gimbal control board --- which would otherwise have
protruded too high and hit the mount --- was mounted inside the
anti-vibration mount on velcro. Various adjustments were made to
ensure it does not hit the upper plate of the anti-vibration mount.

The anti vibration mount is attached to a laser cut board designed to
fit the landing gear and the onboard computer. The anti-vibration
mount is attached with cable ties to bear the load and hot glue to
prevent the parts moving with respect to each other.

The board is reproduced below in Figure~\ref{fig:pc-mount}.

\begin{figure}[h]
  \centering
    \includegraphics[width=0.6\textwidth]{figs/pc-mount}
  \caption{The PC mounting board, as rendered by SolidWorks.}
  \label{fig:pc-mount}
\end{figure}

It's not immediately obvious how that mates with the anti-vibration
mount, so Figure~\ref{fig:pc-avm-mount} shows the designed plate
mating with a reconstruction of the critical parts of the
anti-vibration plate.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\textwidth]{figs/pc-avm}
  \caption{The key (interior) parts of the anti-vibration mount (front), with the PC mount plate (back) showing the shared cutouts for cable ties.}
  \label{fig:pc-avm-mount}
\end{figure}
The board is mounted to the landing gear with cable ties and hot glue.
\newpage~\newpage
\section{Concluding remarks}
\label{sec:concluding-remarks}

Figure~\ref{fig:mk2} is a picture of the complete assembly.

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{figs/mk2}
  \caption{The completed assembly.}
  \label{fig:mk2}
\end{figure}

The total weight of the assembly is around 1.4kg, not including batteries.

\chapter{Construction: Software}
\label{sec:software}

The software is built on ROS, the Robot Operating System
\cite{rosos}, using the Indigo version. ROS is built around the
concept of \emph{nodes} --- lightweight, reusable programs that perform a small
part of robot operation --- that are coupled together by passing
around \emph{messages} through use of a publish-subscribe mechanism.

ROS also provides a \emph{transform} mechanism. Loosely, a transform
gives the position of one frame of reference in terms of another frame
of reference. For example, a transform could provide the position of a
sensor with respect to robot body --- a `fixed' transform. Another
example would be a transform that gives the position of the robot body with
respect to some reference frame --- a dynamic transform.

Because ROS is such a modular system, it is helpful to consider an
overview of the setup before the parts are discussed in
detail. Figure~\ref{fig:roschain} shows a graphical representation of
ROS nodes used in the program, as well as the main topics and
transforms. Grey nodes were provided by ROS, while white nodes were
either written or significantly modified during the project.

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{figs/roschain}
  \caption{Graphical representation of ROS nodes, data passed between
    them, and key transforms published. Grey nodes represent nodes
    provided by ROS. White node were written or significantly modified
  during the project.}
  \label{fig:roschain}
\end{figure}
\newpage
There are three frames of reference in Figure~\ref{fig:roschain}:
\texttt{world}, \texttt{odom}, and \texttt{base\_link}. They are
(mostly) named in accordance with ROS standard REP105 \cite{rep105},
and are defined as follows:
\begin{itemize}
\item \texttt{world} provides a fixed world reference frame. It is
  defined such that the robot starts at the origin.\footnote{For
    compliance with REP105, this frame should be named
    \texttt{map}. However, early development wasn't REP105 compliant
    and the name hasn't been updated yet.}
\item \texttt{base\_link} is a frame of reference that is fixed to the
  robot. That is, if there's a sensor attached to the robot, the
  sensor's position remains at a constant position with resepect to
  this frame.
\item \texttt{odom} is difficult to define except in terms of its
  relationship to other frames. The position of \texttt{base\_link} is
  determed by the polar scan matcher with respect to the \texttt{odom}
  frame, and the \texttt{odom} frame is positioned by
  \texttt{tree\_fix} in order to make sure the \texttt{base\_link} frame
  is positioned correctly: that is, the \texttt{world} to
  \texttt{odom} transform is a correction only: \texttt{odom} doesn't
  represent any real position.
\end{itemize}

This is understood most easily through Figure~\ref{fig:rostf}.

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{figs/rostf}
  \caption{A diagramatic explanation of the ROS transforms used.}
  \label{fig:rostf}
\end{figure}

\newpage
\section{\texttt{scan\_to\_height}}
\label{sec:scan_to_height}

As explained in Subsection~\ref{sec:height-meas-setup}, the last few
points of the laser scan are reflected downwards to get a measurement
of height.

This node splits the received laser scan (topic \texttt{/scan}) into
two scans: \texttt{/height\_scan}, which contains just the points for
the downward reflected height, and \texttt{/clean\_scan} - the scan
with the downward reflected points removed.

The median of the downward points is published to
\texttt{/height\_raw}. However, this value is very noisy.

To reduce the noise, the value is then placed in a 10 point moving
average, and that value published in \texttt{/height}. This has a very
low noise --- in the order of a couple of centimetres --- but because
there are 40 scans per second, still very rapid response to changes in
altitude.

So far, this value is unused. Future work should integrate this into
control of the hexacopter.

Future work for this node is limited to correcting two sources of
error.  Firstly, the mirror is not at a perfect downwards angle, so
there is a multiplicative error. Secondly, there's an additive error
due to the distance between the sensor and the mirror, and due to
losses caused by the mirror surface. These should both be corrected
for.

\section{Scan Filtering}
\label{sec:scan-filtering}

Having the laser scanner mounted in the landing gear means that
various points of the scan will always hit the landing gear. If these
are not filtered out, they cause the polar scan matching to perform
very poorly.

A node provided with ROS is used to filter points from the scan that
would be within the footprint of the hexacopter. This significantly
improves performance.

Various other filters were explored, including a shadow remover, and
an interpolation filter. Neither improved performance.

\section{Polar Scan Matcher}
\label{sec:polar-scan-matcher}

The polar scan matcher is based on \cite{polarscanmatching}, as
explained in Section~\ref{sec:polar-scan-matching}.

This node posed a number of challenges.

Firstly, while code was purported to exist for ROS, it no longer
existed in the main \texttt{scan\_tools}
repository\footnote{\url{https://github.com/ccny-ros-pkg/scan_tools}}. A
copy was located in another repository and copied over.

Secondly, the code was old - circa ROS Electric, and would not compile
on more recent versions of ROS due to changes in various libraries,
specifically the transform datatypes.\footnote{See:
  \url{http://wiki.ros.org/geometry/bullet_migration} and
  \url{http://wiki.ros.org/fuerte/Migration}} Fortunately, the
provided migration scripts proved sufficient to migrate the code and
have it compile.

Thirdly, the code once compiled did not run, but would crash almost
immediately after launching. The code initially expected the scanner
to report a range of 0 for out of range points, but the scanner was
instead reporting NaN (not a number) values instead. Fixing the
assumption lead to the polar scan matcher running reasonably well.

These changes were sufficient to get the laser scanner working
reasonably well indoors, but completely inadequately outside. The
first attempt to fix this was by replacing the scanner with a much
more capable scanner (see the Mk II: Subsection~\ref{sec:mk-ii}). This
lead to some improvement but not enough to make the system usable.

The following changes were also required for acceptable outdoor
performance:

\begin{description}
\item[Points required for a match] By default, the polar scan matcher
  node requires 100 points be matched from between two scans for the
  match to be considered successful. This worked well inside but
  poorly outside. Dropping the threshold to 10
  points improved matching noticeably, but not to the point of being
  acceptable.
\item[Negative Distances] Error reports from the polar scan matcher node
  showed that occasionally negative distances were found. Tracing
  these back, it was discovered that the scanner node itself was
  outputting negative distances. These were discarded in an early
  stage of processing, leading to slightly improved performance.
\item[Median Filter] A close, time-consuming examination of the code
  revealed that one of the pre-processing steps was a median filter.

  The median filter replaces each point with the median of the points
  around it. Formally, it works as follows:
  \IncMargin{1em}
  \begin{algorithm}
    \KwIn{Laser scan $s$}
    \KwOut{Laser scan $s'$}
    \BlankLine
    \For{$i \leftarrow 0$ \KwTo $(\text{length of }s - 1)$}{
      \tcp{Collect 5 points: the point and two points either side.}
      $r \leftarrow s[(i-2) \ldots (i+2)]$ \;
      $r' \leftarrow \text{bubble\_sort}(r)$ \;
      \tcp{Replace the point with the central (3rd) point of $r'$}
      $s'[i] \leftarrow r[2]$ \;
    }
    \caption{Pseudo-code for the median filter algorithm}
  \end{algorithm}

  While this algorithm works well indoors, where there are long
  straight runs, the algorithm unfortunately dramatically
  impedes outdoor performance. Disabling this filter entirely lead to
  vastly superior outdoor behaviour.
\end{description}


\section{Tree Detection \& Localization}
\label{sec:tree-detection-localization}

In keeping with the ROS philosophy of having small, specialised and
reusable nodes, the process is broken up into two nodes: one which
takes laser scans and detects trees, and one which uses the detected
trees to correct the polar scan matching-derived position to a true
position.

\subsection{Tree Detector: \texttt{tree\_detector}}
\label{sec:tree_detector}

The tree detector node simply detects trees from a laser scan.

It's presently a very primitive process, but works sufficiently well
when the following assumptions are met:
\begin{itemize}
\item Trees are close. More precisely, a \emph{map range} is defined,
  and points that compose the trees must be within the square
  (-\texttt{MAP\_RANGE}, -\texttt{MAP\_RANGE}) to (\texttt{MAP\_RANGE},
  \texttt{MAP\_RANGE}). The choice of \texttt{MAP\_RANGE} is a trade-off
  between detection range and speed and memory usage. However,
  increasing range has diminish returns, as the distance between
  detected points grows with distance, making it harder to accurately
  detect trees. Experimentally, 6 metres provides good results.
\item There are no other significant clusters of points (e.g. no
  walls) within the map range.
\end{itemize}

The process proceeds as follows:
\begin{description}
\item[Drop scans] Only 1 out of every $N$ scans are processed, where
  $N$ is a parameter currently set to 10. This is necessary to ensure
  that there's not a backlog of messages out of the node. Drop the
  other $N-1$ scans without processing them.
\item[Convert the laser scan into an image] For speed and memory usage
  reasons, only points within the map range are included. Presently,
  the intensity of the reading from the laser scan is ignored, and
  readings are mapped either to pure white if they fall within the map
  square, and black if they don't fall within the map.
\item[Blur] A gaussian blur is applied to the image. This serves two
  purposes:
  \begin{itemize}
  \item It reduces the effect of noise on future stages - a stray
    reading will be blurred into basically nothing.
  \item A scan of a tree at a few metres distance will not be a
    contiguous line, due to the angle between the readings. This leads
    to it not being detected as one feature, but as several, which is
    undesirable. Blurring tends to create smoother, contiguous runs
    that are easier to detect.
  \end{itemize}
\item[Threshold] A threshold is applied to further reduce noise.
\item[Circle detection] Actually detecting circles was more difficult
  than expected. Four major approaches were attempted:
  \begin{itemize}
  \item The OpenCV built-in ``Hough Circles'' detection process. This
    failed to yield any results at all, even on artificial perfect
    circles and with supplied sample code. This may have been due to
    OpenCV version problems, or a misunderstanding of the parameters.
  \item Feature detection with a semi-circle also failed; which is
    apparently due to the same root cause as the Hough Circles
    failure.
  \item MSER---maximal stable external regions---a way to detect
    `blobs', was mostly successful, but far too slow.
  \item The approach ultimately adopted was to find features with more
    points than a given threshold, and find the minimum enclosing
    circle. While not strictly accurate, it provides sufficient
    accuracy, especially when there are a sufficiently large number of
    points, for the algorithm to work well.
  \end{itemize}
\item[Publish points] The centers of the detected trees are published
  as a point cloud to the \texttt{/trees} topic. They're published in
  the same frame of reference that they're detected in ---
  \texttt{/laser}, which in the current implementation is tied to
  \texttt{/base\_link}.
\end{description}

Significant future work is needed to make this node more robust and
versatile, especially in an outdoor environment that contains both
trees and other objects. The biggest improvement needed is to replace
the circle detection algorithm with a proper one. Either the Hough
Circles function in OpenCV could be debugged and used, or perhaps
RANSAC circle detection (e.g. as described in \cite{ransac}) could be
used in order to reduce computational requirements. Either way, a
proper circle detection algorithm should prevent features like walls
from being inadvertently detected as trees.

Furthermore, there are a number of improvements that can be made to
the speed and robustness of the algorithm.
\begin{itemize}
\item The map uses 1 pixel per centimeter. This provided good early
  experimental results, but is quite costly in terms of both memory
  and speed. This could probably be reduced, especially if a different
  algorithm was used.
\item Presently, the points are placed into a map, which, for memory
  and speed reasons, is fairly small. However, the map is very sparse,
  because in an outdoor environment most of the points are out of range.
  It should be fairly straightforward to create several smaller maps
  wherever points are detected, decreasing memory usage, increasing
  speed, and increasing detection range.
\item A gaussian filter is used with quite a large kernel ($11 \times
  11$ pixels). Alternative, faster filters should be evaluated.
\item The entire Python code should be re-written in C++, which would
  probably result in a \emph{significant} speed up.
\end{itemize}

Finally, it would be highly desirable for many of the hardcoded
parameters to be made configurable in the standard ROS way.
\newpage
\subsection{Tree Localization: \texttt{tree\_fix}}
\label{sec:tree_fix}

The \texttt{tree\_fix} node uses the trees published by
\texttt{tree\_detector} to perform primitive SLAM. Specifically, \texttt{tree\_fix}:
\begin{itemize}
\item Builds up a map of the trees in the environment.
\item Uses that map and the detected trees to localise the robot,
  providing a correction to the pose estimate provided by the polar
  scan matcher.
\end{itemize}

In very broad brush strokes, the process is as follows:
\begin{itemize}
\item Assume that the change between this scan and the last scan is
  probably not too great, seeing as the \texttt{tree\_fix} package
  publishes a new point cloud on \texttt{/trees} several times a
  second. Therefore, we can use the last correction to gain a good
  first estimate of what the current correction should be.
\item Find the static points closest to the new points, so we have a
  two sets of points of equal length. 
\item Then it becomes the case that:
  \begin{equation}
    \label{eq:1}
    P' = RP + T + N
  \end{equation}
  That is, the new points ($P'$) is the rotation ($R$) of the original
  points ($P$) plus a translation ($T$) plus some noise/error ($N$).

  Therefore, we can determine the $R$ and $T$ that minimises the error
  between the known points and $P'$.
\item We use the $R$ and $T$ to transform the complete set of new
  points. 
\item Points that cannot be matched to existing map points are
  determined to be new trees and added to the map.
\end{itemize}

Implementation details make the algorithm more complex in
practise. The implemented algorithm is shown in
Figure~\ref{fig:tree_fix} and fleshed out in more detail below.
\newpage
\begin{figure}[h!]
  \centering
  \includegraphics[width=0.7\textwidth]{figs/tree_fix}
  \caption{Flowchart describing the operation of \texttt{tree\_fix}}
  \label{fig:tree_fix}
\end{figure}
\newpage
The algorithm as implemented is:
\begin{itemize}
\item Keep track of the last translation and yaw correction. Initially
  this starts at a translation of (0,0) and a yaw of 0 radians.
\item Use the last known translation and rotation to transform the
  detected points into `uncorrected points'.
\item The uncorrected points are then compared to the known
  points. Points are matched to their nearest known point, so long as
  the nearest known point is no further than a given threshold away.
\item If there are two or more points in common, a roto-translation (a
  rotation plus a translation) is then calculated such that the RMS
  error is minimised. This is done as follows.

  \IncMargin{1em}
  \begin{algorithm}
    \KwIn{Sets of points $A$, $B$}
    \KwOut{Rotation matrix $R$, translation matrix $T$}
    \BlankLine
    \tcp{Center A and B.}
    $A_{centroid} = $mean$(A)$\;
    $A' \leftarrow A - A_{centroid}$\;
    $B_{centroid} = $mean$(B)$\;
    $B' \leftarrow B - $mean$(B)$\;
    \BlankLine
    \tcp{Try a set of rotations.}
    \tcp{To be precise, try $N$ points in $[-W, W]$.}
    $err_{min} = \infty$ \;
    $points \leftarrow $linspace$(-W, W, N)$ \;
    \BlankLine
    \ForEach{$\theta \in points$}{
      $R = $ rotation matrix for $\theta$ \;
      $B_{rotated} = B' \times R$ \;
      $err = $rms\_error$(B_{rotated}, A')$\;
      \If{$err < err_{min}$}{
        $err_{min} = err$\;
        $\theta_{best} = \theta$\;
      }
    }
    \BlankLine
    \tcp{Find the translation that aligns the rotated center of $B$
      with the center of $A$.}
    $R = $ rotation matrix for $\theta_{best}$ \;
    $T = -R \times B_{centroid} + A_{centroid}$\;
    \BlankLine
    \Return{(R, T)}
  \end{algorithm}
 
  Previously, this was implemented using the Singular Value
  Decomposition method. However, this was found to be less reliable,
  because the SVD can include a \emph{reflection} as well as a
  rotation and a translation. This is physically impossible, but due
  to the dense and largely similar nature of the forest, it was
  returned quite often by the SVD based algorithm. The
  roto-translation, while vastly less efficient, is much more reliable.


\item If the common set only contains one point, then a simple
  translation is calculated, and it is assumed there is no rotation.
\item If there are no points in common, the transform is assumed to be
  the identity: no translation or rotation.
\item The translation is applied to all the uncorrected points, such
  that they become corrected points.
\item The corrected points are then tested against the known map
  points. If there is no map point within a given threshold distance
  of a corrected point, the corrected point is added to the map.
\item The map and the corrected points are published for visualisation
  purposes.
\item If two or more common points were detected, the correction
  converted from being in terms of the previous correction into being
  in terms of the world frame. Because the correction is prone to
  considerable jumps, it is averaged with the previous correction
  before being published.
\item If less than two points were detected, the previous correction
  is republished. It is important for smooth operation that a
  correction is published, even if it's the same - otherwise
  transforms can start to fail, leaving the system without an estimate
  of position.
\end{itemize}

Significant future work is needed on this node.  Firstly, it can be
prone to large jumps - it would be good to replace it with some form
of positioning that provides more smooth positioning. Perhaps this
could be done by integrating the position information from the polar
scan matcher and the tree matcher into a single processing node,
utilising something like a Kalman filter.

Secondly, it has no ability to update its idea of known trees. It
cannot perform meaningful loop closure or indeed any form of update
other than recognising a new tree. This should be addressed.

Lastly, this work replicates work done by others on scan matching and
SLAM. Replacing the point matching algorithm described with a point
matching algorithm described in the literature should be considered.
As many scan matchers are designed for laser scans or other dense
point clouds, it may be necessary to make some changes for the vastly
more sparse point cloud from the tree detector. Furthermore, the
literature relating to SLAM should be consulted to allow more
meaningful map updates.

\section{Software Usage}
\label{sec:software-usage}

This sections outlines how the software was used in practise.

The onboard PC used \texttt{rosbag} to record scan data and save it to
the CF card. In early stages of the project, the polar scan matcher
and visualisation were also conducted on the onboard computer, but the
lack of OpenGL support make \texttt{rviz} very slow, which had
knock-on effects on the rest of the stack.

As such, for much of the project, data was recorded on the onboard PC,
then transferred to a low-powered laptop for processing. The
processing was required to be real-time, using \texttt{rosbag}'s
ability to output timestamped messages. Furthermore, any advantage
that the laptop had by being dual-core was obviated by the significant
processing requirements of \texttt{rviz}. As such, the processing that
was run on the laptop should also run in real time with no or minimal
tuning on the onboard computer.

\chapter{Results}
\label{cha:results}

The system can best be understood by building it up block by
block. This approach allows the performance of each major component to
be understood individually.

\section{Polar Scan Matching alone: indoor}
\label{sec:psm-indoor}

Firstly, we consider just the polar scan matcher by itself, indoors.

The polar scan matcher provides generally adequate performance inside
a room, but tends to be subject to drift and jumps. 

This is illustrated in Figure~\ref{fig:psm-indoors}, which was taken
in the Research School of Information Sciences and Engineering (RSISE)
building at the Australian National University. The laser scanner
started in the room in the top right corner of the scan, then exited
the room, walked straight to the corner, then turned. The angles
should be right angles, rather than the non-right angles observed.

It's worth noting that the laser scans tend to go in `blocks':
matching will be very good for a short period (for example in a room)
then will have a `jump' where error rises significantly.

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{figs/indoor}
  \caption{Performance of polar scan matcher alone, indoors.}
  \label{fig:psm-indoors}
\end{figure}

A few observations can be made about the jumps:
\begin{itemize}
\item Part of the reason was traced back to sensor/recording
  error. \texttt{rosbag}, which was used to record the data, saves the
  data out in chunks of a certain size. By default, the chunk size is
  768 KB. Unfortunately, writing that much data out to the CF card
  used in the onboard computer caused noticeable delay. This was
  reduced later in development to 256 KB, which reduced the delay.
\item Performance in corridors was particularly bad. This was at least
  partially due to the self-similarity of corridors: without either
  being able to see the end of a corridor or other distinguishing
  landmarks, and with no IMU or other form of odometry, it becomes
  difficult to distinguish movement from staying stationary.
\item Turning corners and leaving rooms seemed to be particularly
  large sources of error. This could be due to the particularly large
  number of points changing quickly, with very few points remaining
  across the turn.
\end{itemize}

It was also interesting to note that if one of the SLAM systems that
is available with ROS was added to the system (for example
\texttt{slam\_gmapping}), performance improved significantly
indoors. However, the chunking issue identified above still tended to
cause problems.

As indoor navigation was not a priority, merely an early way to test
the system, no major work was invested in ironing out defects. Rather,
the system was tested outdoors.

\section{Polar Scan Matching alone: outdoor}
\label{sec:psm-outdoor}

The polar scan matcher was then tested outdoors.

Initially, the system was entirely unusable, not detecting motion in
any usable way whatsoever. Firstly, a greater range laser scanner was
tried. (This necessitated significant hardware work, resulting in the
Mk II: see Section~\ref{sec:mk-ii}.) However, ultimately various fixes
to the software were required. These are explained in
Section~\ref{sec:polar-scan-matcher}.

Once those fixes were deployed, the polar scan matcher provided
estimates which were roughly correct, especially in the short term,
but which tended to drift unacceptably. The drift was especially
visible on tree trunks, which became ``blurred'', as shown below in
Figure~\ref{fig:blur-detailed}. 

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.8\textwidth]{figs/blurring}
  \caption{``Blurring'' experienced by uncorrected outdoor polar scan matching.}
  \label{fig:blur-detailed}
\end{figure}

The cumulative drift and error is
significant. Figure~\ref{fig:psm-outdoor} shows the result of walking
the scanner assembly around a clump of trees at ANU. (See
Section~\ref{sec:tennis-court} for full details of the location.) The
path taken was a loop, so the net translation should be zero. However, a
large translation is observed; trees do not stay in the same place and
there is lots of noise.

\begin{figure}
  \centering
  \includegraphics[width=0.9\textwidth]{figs/psm-outdoor}
  \caption{PSM only, outdoors}
  \label{fig:psm-outdoor}
\end{figure}

Evidently further work was required for accurate localisation.
\newpage~\newpage
\section{Tree-based localization}
\label{sec:tree-based-local}

Adding the tree-based localization described in
Section~\ref{sec:tree-detection-localization} led to significant
improvement in results. Two major outdoor locations were tested.

\subsection{Tennis Court}
\label{sec:tennis-court}

The ``tennis court'' location is a clump of trees near some tennis
courts on the ANU campus. The trees are pictured in
Figure~\ref{fig:tennis-trees}.

\begin{figure}
  \centering
  \includegraphics[width=0.6\textwidth]{figs/tennis-1}\\
  ~\\
  \includegraphics[width=0.6\textwidth]{figs/tennis-2}\\
  ~\\
  \includegraphics[width=0.6\textwidth]{figs/tennis-3}\\
  \caption{Various pictures of the ``tennis court'' clump of trees.\\
  \textbf{Top:} View from the start of the loop (the dented metal
  rail).\\
  \textbf{Middle:} View from mid-way though the loop.\\
  \textbf{Bottom:} View from towards the end of the loop.}
  \label{fig:tennis-trees}
\end{figure}

The hexacopter landing gear assembly was walked in a loop through the
clump of trees. The results---the path taken and the map of trees
detected---is shown in Figure~\ref{fig:tennis-results}. The data bag
for this and other trials is available on the project repository.

\begin{figure}
  \centering
  \includegraphics[width=0.9\textwidth]{figs/tennis-results}\\
  ~\\
  \includegraphics[width=0.9\textwidth]{figs/tennis-results-annotated}
  \caption{Tennis Results. \textbf{Top:} raw results. \textbf{Bottom:}
  annotated results.}
  \label{fig:tennis-results}
\end{figure}

In the results:
\begin{itemize}
\item The \emph{red line} represents the path travelled. The line is a
  collection of arrows, where the base of each arrow represents the
  position at that instant, and the arrow is facing in the direction
  the landing gear was facing.
\item The \emph{green dots} represent trees \emph{currently being
    detected} by the tree detection algorithm. In this case, two trees
  in view of the start/end position are detected.
\item The \emph{blue dots} represent the position of every tree known
  to the system, the `map'.
\end{itemize}

The results have been annotated to highlight several
features. Firstly, the arrow shows the initial direction of movement
along the loop. The labelled regions are as follows:
\begin{enumerate}[A:]
\item This region shows the landing gear being rotated around a
  point. This was done to ensure that the scanner remained in view of
  multiple trees for as much of the route as possible.
\item This region shows the landing gear being walked sideways: unlike
  early in the path, the arrows are perpendicular to the direction of
  travel. Again this was done to ensure that the laser scanner had a
  good view of trees.
\item This shows a simple `jump' in position, as the system goes from
  being able to see one tree, and therefore not being able to do a
  position correction, to seeing two trees, and being able to do a
  position correction. The averaging algorithm reduces the level of
  discontinuity in the position, but the discontinuity is still
  observable.
\item This shows a more complicated `jump', as the system became
  momentarily confused about its position, and then recovered.
\end{enumerate}

Because the path was a loop, we can consider how accurately the path
closes. Over a distance of around 40m each way, the final position was
virtually indistinguishable from the original position, with error of
around 10cm.

As such, we can conclude that the algorithm was highly successful for
this set of trees.

\subsection{Roadside}
\label{sec:roadside}

The ``roadside'' location is another clump of trees on the ANU
campus. The trees are pictured in Figure~\ref{fig:roadside-trees}.

\begin{figure}
  \centering
  \includegraphics[width=0.6\textwidth]{figs/roadside-1}\\
  ~\\
  \includegraphics[width=0.6\textwidth]{figs/roadside-2}\\
  ~\\
  \includegraphics[width=0.6\textwidth]{figs/roadside-3}\\
  ~\\
  \caption{Roadside trees.\\\textbf{Top:} View from near the start of
    the loop.\\\textbf{Middle:} View from towards the end of the loop,
  looking forwards.\\\textbf{Bottom:} View from towards the end of the
  loop, looking backwards towards the start.}
  \label{fig:roadside-trees}
\end{figure}

Again the hexacopter landing assembly was walked in a loop, with the
results plotted in Figure~\ref{fig:roadside-results}.

\begin{figure}
  \centering
  \includegraphics[width=0.45\textwidth]{figs/roadside-results}
  ~
  \includegraphics[width=0.45\textwidth]{figs/roadside-results-annotated}
  \caption{Roadside results. \textbf{Left:} unannotated
    results. \textbf{Right:} annotated results}
  \label{fig:roadside-results}
\end{figure}

The symbols are the same as in the previous location.

Points to note include:
\begin{enumerate}[A:]
\item The landing gear was again walked perpendicular to the direction
  it was facing at the end of the loop in order to get a clear
  reading.
\item There were a number of significant jumps. This jump has been
  highlighted because it occurs after a reasonably large chunk of
  having no trees detected at all (note the large `gap' in trees
  directly above it on the map), so it provides a good example of the
  amount of drift experienced over moderate distances when using PSM
  alone.
\item Unlike the previous example, this example does not end with two
  trees visible, but only one. As shown here, the detected tree starts
  to drift off from the known tree, because corrections can only be
  correctly estimated with two trees. This demonstrates that PSM
  drifts away from the ground truth even in the absence of motion.
\end{enumerate}

The return to origin behaviour is excellent when in view of two trees,
but does, as this example shows, tend to drift away when only one tree
is in view. However, once that is accounted for, the accuracy is very
good --- this time over a distance of about 60 meters each way.

\subsection{Negative results}
\label{sec:negative-results}

Along with the two successful results above, there were a number of
unsuccessful trials. While all the trials were different, a number of
observations can be made, which further characterise the system.

There are two major reasons for unsuccessful trials: sensor and
recording errors, and algorithm errors. Recording errors will be
detailed here, and algorithm errors discussed in
Section~\ref{sec:analysis-results}.

There were two major sources of recording error. Firstly, the chunking
error discussed in Section~\ref{sec:psm-indoor}. Secondly, there were some
issues with the recorded data missing the start and/or end of the
route. This was mitigated by using a smaller chunk size, and
ultimately eliminated by waiting 10--15 seconds from when the system
started.

\subsection{Conclusion --- walking only}
\label{sec:concl-walk-only}

The results from walking the landing gear around the two locations are
highly positive.

In short, they demonstrate that:
\begin{itemize}
\item  the hardware works and is capable of
handling the low-frequency vibrations and general `wobble' caused by
being walked around.
\item the software works, both in terms of being able to record and
  replay data, and also in the sense of being able to successfully
  localise the platform as it is being walked around.
\item the software works in both locations, so it is not overly
  specialised for a single location or set of assumptions.
\end{itemize}

However, just walking around leaves a few questions: can the hardware
handle flying, especially in terms of high frequency vibrations; and
can the software handle the extra `noise' in the data caused by flying?

\section{Flying}
\label{sec:flying}

The landing gear was attached to one of ANU's hexacopters. The
hexacopter power was kept separate from the payload power, in order to
prevent any drops in voltage from sudden acceleration from causing
issues with the computer.

The hexacopter was able to take off, but required around 70\%
throttle, suggesting the overall weight should be reduced.

Two flight tests were undertaken, which are explored below.

\subsection{RSISE}
\label{sec:rsise}

The first flight test was conducted outside the Research School of
Information Sciences and Engineering at ANU. The clump of trees used
is shown in Figure~\ref{fig:rsise-trees}. The hexacopter in flight is
shown in Figure~\ref{fig:rsise-flying}.

\begin{figure}
  \centering
  \includegraphics[width=0.9\textwidth]{figs/rsise-trees-1}\\
  ~\\
  \includegraphics[width=0.9\textwidth]{figs/rsise-trees-2}
  \caption{RSISE Trees\\\textbf{Top:} View showing the front/side
    showing the big tree, 2 front trees
    and the 2 back trees.\\\textbf{Bottom:} View from the side, looking
  in the opposite direction.}
  \label{fig:rsise-trees}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.9\textwidth]{figs/rsise-flying}
  \caption{The hexacopter flying near the RSISE trees. The photo was
    taken facing away from the trees, so the trees identified in the
    results are not in frame.}
  \label{fig:rsise-flying}
\end{figure}

The flight path did not attempt to weave between the trees, rather it
simply flew from side to side, facing the clump of trees, at a
distance of a few meters.

The flight was highly successful. Once the hexacopter had taken off,
it was able to correctly locate the trees and use them for
localization, even with changes in altitude. It also shows the
altitude measurement is both smooth and responsive.

Because the flight was not a loop, plotting the entire path is not
particularly useful or informative. Instead,
Figure~\ref{fig:rsise-results} shows a snapshot of the 3D path taken by
the hexacopter, as it ascends.

\begin{figure}
  \centering
  \includegraphics[width=0.9\textwidth]{figs/rsise-flying-results}
  \caption{RSISE flight results, showing a snapshot of the
    flight.}
  \label{fig:rsise-results}
\end{figure}

The software kept accurate localization so long as the hexacopter was
at a reasonable height: more than 1m or so above the ground.

\newpage
\subsection{Tennis Court}
\label{sec:tennis-court-1}

The second flight test was conducted in the same location as in
Section~\ref{sec:tennis-court}. 

Determining the flight path was slightly more complex in this
case. The data was noisy, particularly around takeoff and landing. In
particular, the landing involved a turn conducted when the polar scan
matcher was pointed across a car-park, and was too high to observe any
points. Thus the turn cannot be computed, and the system gets horribly
confused.

As such, the flight path with the take-off and landing omitted is
shown below in Figure~\ref{fig:flying-tennis-path}. Some stills from
the 3D view are shown in
Figure~\ref{fig:flying-tennis-3D}. Figure~\ref{fig:flying-tennis-pic}
shows a picture of the hexacopter in flight.

\begin{figure}[h]
  \centering
  \includegraphics[width=0.9\textwidth]{figs/tennis-flying-results}
  \caption{The path taken by the hexacopter through the tennis court trees.}
  \label{fig:flying-tennis-path}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{figs/tennis-flying-1}\\~\\
  \includegraphics[width=0.8\textwidth]{figs/tennis-flying-2}
  \caption{Two 3D snapshots of the flight.}
  \label{fig:flying-tennis-3D}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=0.9\textwidth]{figs/tennis-flying-pic}
  \caption{A picture of the hexacopter in flight through the tennis court trees.}
  \label{fig:flying-tennis-pic}
\end{figure}

It's difficult to analyse the flight in terms of return to origin, but
it's worth noting that the path shown accurately tracks the path
taken, and certainly with enough accuracy for navigation and obstacle
avoidance.
\newpage
\subsection{Conclusion --- flying}
\label{sec:conclusion-flying}

The big question remaining after the successful walking tests was
whether or not the system could handle the high frequency vibrations
caused by being flown. 

The results show that the system can accurately localise itself when
flying. 

\chapter{Discussion}
\label{cha:discussion}

\section{Analysis of results}
\label{sec:analysis-results}

Understanding the errors in the results is not
straightforward. Broadly, error can be categorised into \emph{sensor
  error}, and \emph{algorithmic error}. Sensor error from the laser
scanner appears to be small, and vibrations from flying the hexacopter
does not seem to increase it. Some error which could most accurately
be described as sensor-related was due to timing issues in recording
data, but that was easy to address (see Section~\ref{sec:psm-indoor}).

The algorithmic error comes from the polar scan matcher, the
tree-based localization and the interaction between the two. We
explore the issues in each.

\subsection{Analysis of PSM-related error}
\label{sec:psm-error}

The negative results from walking around provided a lot of examples of
causes of error.

Firstly, the polar scan matcher does not deal well with circling a
single tree. This makes sense: a circle from any angle looks the same,
so it's not surprising that the algorithm struggles. This is
especially the case when there is only 1 tree in view.

More broadly, the polar scan matcher works much better the more points
it can match. Sparse clumps of trees surrounded by clear space tend to
work much worse than denser clumps of trees, which is why many of the
negative results were for the RSISE trees and the results for the
tennis courts and roadside were much more positive.

Lastly, foliage did not seem to interact well with the PSM.

Furthermore, errors in PSM tended to interact badly with the
tree-based localisation: see Section~\ref{sec:interaction}.

\subsection{Analysis of tree-based localization error}
\label{sec:tree-error}

Tree based localisation is itself prone to two different types of
error: error in detecting trees, and error in using those trees for
localization.

\subsubsection{Tree Detection}
\label{sec:tree-detection}

The primitive nature of the tree detector affects its accuracy. 

Firstly, there's a tradeoff in the number in tree points required for
the detection of trees. If too many points are required, trees have to be very
close before they're detected. If too few points are required, a
single tree can be detected as multiple trees, and there are increased spurious detections.

More broadly, the detection algorithm detecting features rather than
circles creates problems.

\begin{description}
\item[Inability to deal with different classes of feature] Using the
  minimum enclosing circle (MEC) with features means that any shape is
  treated as a circle. This makes the algorithm unsuitable to be used
  in mixed environments, and also makes it perform poorly in the
  presence of people in the field of view.
\item[Cannot use radii] The MEC detection is quite unstable: rather
  than detecting a stable circle with a near-stationary centre, the
  centre and especially the radius fluctuate wildly. This means the
  radius cannot be published and used for tree matching.
\item[Cannot detect distant trees] An inevitable feature of laser
  scanners is that the detected points spread out. The minimum
  detectable width of an object at 10m is 130mm with the UTM-30LX
  scanner used (see Section~\ref{sec:mk-ii}). A decent sized tree
  should still get 3 or 4 points, which is enough to fit a
  circle. However, because the MEC detection requires many, many
  points, and requires them to be close together when mapped to
  pixels, it cannot detect distant trees.
\end{description}

Ultimately, these issue can only be solved by moving to an algorithm
that actually detects circles.

Further issues:
\begin{itemize}
\item The tree detector is also easily confused by foliage.
\item The system models trees as perfect vertical columns of infinite
  height. Obviously this is not correct. A more appropriate model
  should allow trees to change height, to fork, to have foliage, and
  to have finite height.
\end{itemize}

\subsubsection{Tree Localization}
\label{sec:tree-localization}

The tree localization is also largely hamstrung by its
nearest-neighbour algorithm. In short, there is no way to accurately
locate a small set of points within a larger set of points without
first having a position estimate. This means that any estimate that
pushes the trees either beyond the threshold for nearest-neighbour, or
pushes them closer to a different recorded tree will cause the points
to fall out of sync, and once they are out of sync they cannot go back
into sync of their own accord.

This is not an easy problem to solve, especially in a time-efficient
way. 

For example, finding the best match for 2 points in a map with 20
points requires testing $20 \times 19$ different pairs. Trying to
match 3 points requires at worst $20 \times 19 \times 18$. 

The process is further complicated because the algorithm cannot be
sure that all the points that have just been detected map to points on
the map: some --- or all! --- of them could be new detections.

In addition, forests tend to look similar at small scales. Perhaps
it's simply a quirk of the two environments mapped, but the a lot of
pairs of trees have similar distances. This makes generic matching
with only small numbers of trees particularly difficult.

Integrating the radii of trees into the matching algorithm would
reduce the similarity. However, at the moment there's the assumption
that the trees are a perfect column, with a constant radius the whole
way around. If the measurements were not made at very similar heights,
this assumption would fall apart, again complicating matters.

However, all of this is ignoring part of the information we know. Our
system is binary --- for any given position, there is a tree or there
is not. This is a nice simple way of understanding the world, but it
does not encapsulate all the information we have: we also \emph{know
  that some areas are empty}. We can use this: if our alignment tells
us that we should place a tree in an area that we know is empty, we
know we have an incorrect alignment. In other words, we can make use
of probabilistic occupancy grid mapping, albeit at the cost of greater
resources. This is a common approach taken by SLAM systems, including
the ROS package \texttt{slam\_gmapping}.

This approach could also be extended to three dimensions by taking up
the idea of voxels: `volume pixels'. This would enable the system to
work across a range of heights. However, it would massively increase
both complexity and storage requirements, especially with a naive 3D
grid approach. Indeed, the complexity would have almost reached the
level of the stereoscopic camera approach.


\subsection{Interaction}
\label{sec:interaction}

The tree localization system is unfortunately rather sensitive to the
errors occurring in PSM stage. If an error occurs --- even momentarily
--- that causes a tree to be pushed away from it's proper nearest
neighbour and into the neighbourhood of another tree, it will be
matched with that tree, and there is presently very little way to
recover from such an occurrence.

The best way to rectify this would be to replace or integrate the
\texttt{tree\_fix} node with a proper SLAM system.

\subsection{Flight}
\label{sec:flight}

The flight trials raise a number of interesting questions and issues.

Firstly, how should take-off and landing be handled? The localisation
is particularly likely to fail near the ground, especially during
takeoff and landing. Looking at the laser scans, the data seems to be
mostly ``noisy'', and not meaningful.

This could be due to a number of different factors. The uneven nature
of the ground near trees is an obvious candidate. Any deviation of the
scan plane from parallel will also be much more noticeable on near the
ground.

To deal with this, the \texttt{tree\_fix} package was patched to also
consume the \texttt{/height} topic from \texttt{scan\_to\_height}, and
only process the laser scan when the height is above a threshold,
currently 1m.

Future work could look at integrating the low altitude data into a
more complete model, although it would be advisable to discard very
low data - say below 0.5m or so.

Secondly, how should other noisy/erroneous/confusing data be handled? The tennis court
flight in particular features two kinds of noise: a person getting in
the laser scan, and tree foliage.

With regards to people, the algorithm is particularly hamstrung by the
inability to \emph{remove} points from its view of the world. The
noise point stays on the map, and tends to cause problems with
matching. Replacing the `map' with a proper representation that takes
uncertainty into account would help to alleviate this.

With regards to foliage, again better image processing is likely to
be key to fixing this. The problem can be reduced by increasing the
points threshold for a match to 90, but this comes at the cost of
reduced detection. Perhaps a more appropriate fix is to try and find a
circle that includes all the noise and is roughly centred on the tree
trunk. This again ties in well with the concept of a 3D model of trees,
rather than a pure 2D one.

Another apparent fix observed during testing was simply to process
scans at a lower rate: instead of processing 1 in 10 (4 Hz),
processing 1 in 20 (2 Hz) reduced the problem. This is probably an
artefact of the particular data set --- it just managed to skip the
problematic frames by chance. It should not be considered as a
general approach to the problem.

\section{Software: future work}
\label{sec:softw-future-work}

\subsection{Summary of key node-related work}
\label{sec:summary-key-node}

A number of pieces of future work are detailed in the Software
chapter (Chapter~\ref{sec:software}). This section seeks to highlight
what is considered to be the biggest and most pressing aspects of
future work.

Firstly, the filter used in the tree-localization node is a primitive
averaging filter. This should really be replaced with a Kalman
filter. Both the polar scan matcher node and the tree matching
processes provide covariance estimates, and provide or can trivially
provide velocity estimates as well, making them ideally suited to
being combined in this way.

Secondly, the tree detection used in the tree-detector node is so
basic that it is amazing it works as well as it does. Updating it to
actually fit circles properly will vastly increase the stability of
tree detection, reduce error, make it possible to provide and use
radius data, and --- implemented carefully --- it will make the
processing much faster.

\subsection{Future directions in tree detection}
\label{sec:future-direct-tree}

The tree-detector is based around converting the scan from its polar
form into a cartesian form, and then processing that.

A number of laser scan matching algorithms take a similar approach,
but significant efficiency gains were realised in
\cite{polarscanmatching} by processing the scan in its polar form,
without conversion to cartesian form. Would it be possible to realise
similar efficiency gains by detecting trees in polar form? Does the
structure of the polar scan provide opportunities to increase
detection accuracy?

To investigate, some simple simulation was conducted in MATLAB. 
\newpage
Firstly, as shown in Figure~\ref{fig:generic-scene}, a `generic' scene
was transformed from the cartesian form to a polar representation,
where the scan angle forms the $x$-axis, and the radius from the
scanner froms the $y$-axis. This shows the features one would readily
expect from a polar coordinate form: for example, lines become
curves. This seems to show the trees with a somewhat distinctive
shape, but it's hard to determine quite what.

\begin{figure}[h!]
  \centering
  \fbox{\includegraphics[width=0.5\textwidth]{figs/polartest}}\\
  ~\\
  \fbox{\includegraphics[width=0.9\textwidth]{figs/polarpolartest}}
  \caption{A generic scene (top) transformed from cartesian to polar and plotted (bottom). The origin angle has been shifted to aid comprehension.}
  \label{fig:generic-scene}
\end{figure}
\newpage
To get a better idea of what we're looking for,
Figure~\ref{fig:scene-filled} shows what would happen if the entire
tree was known in the polar coordinate-system. (Obviously by the
nature of the laser scanner this isn't possible in an actual scan, but
it's nonetheless helpful to understand the shape.) This reveals an
`egg' shape.

\begin{figure}[h!]
  \centering
  \fbox{\includegraphics[width=0.5\textwidth]{figs/polartest2}}\\
  ~\\
  \fbox{\includegraphics[width=0.9\textwidth]{figs/polarpolartest2}}
  \caption{A generic scene with complete circles (top) transformed from cartesian to polar and plotted (bottom). The origin angle has been shifted to aid comprehension.}
  \label{fig:scene-filled}
\end{figure}

\newpage
A further test in Figure~\ref{fig:6circles} shows a scene with just
trees, different sizes and at different radial distances;
investigating the change this makes in shape.

\begin{figure}[h!]
  \centering
  \fbox{\includegraphics[width=0.5\textwidth]{figs/6circles}}\\
  ~\\
  \fbox{\includegraphics[width=0.9\textwidth]{figs/polar6circles}}
  \caption{A generic scene with complete circles (top) transformed from cartesian to polar and plotted (bottom). The origin angle has been shifted to aid comprehension.}
  \label{fig:6circles}
\end{figure}

Overall, these figures show that cartesian circles, when examined in
polar form, regardless of location, transform into quite a unique
`egg' shape, which can be distinguished from other types of shape,
including lines and corners.

A more rigorous mathematical approach would be required to quantify
the parameters of the shape, but once that is done, it may be possible
to detect circles in the polar form, leading to time and memory
savings.

Furthermore, this process should be more resilient against false
detections because it can take advantage of the polar nature of the
scan: not only does it avoid a large number of multiplications and a
memory accesses, it does not require a continuous (in the Cartesian
frame) set of points that the current detector does. This should allow
the blurring step to be removed. This should help because while the
blurring step is important for the current detection method to work,
it makes it easier to fit a circle to noise. Furthermore, methods
derived from the polar frame may require fewer points to get a
meaningful result, allowing for detection at greater range.

Ultimately, this has potential to be quite a useful avenue for future
investigation.

\subsection{Maintenance}
\label{sec:maintenance}

A final point worth highlighting is software maintenance. A large
amount of effort went into updating the Polar Scan Matcher node to
work with recent versions of ROS. For this code, and the other code
written for this project to continue to be useful in the future, it
will need to be kept up to date, preferably as new versions of ROS
come out, rather than in one big jump several versions down the
line. Fortunately, by placing the data and code on GitHub, it becomes
much easier to use a Continuous Integration platform like
Travis CI\footnote{\url{https://travis-ci.org}} to test against
multiple versions of ROS. Those who continue this project into the
future are strongly encouraged to take up this opportunity to bring
modern software practises to bear on the project.
\newpage
\section{Discussion of hardware}
\label{sec:discussion-hardware}
\subsection{Future work: Weight}
\label{sec:weight}

A major concern regarding the hardware is the weight. Requiring 70\%
throttle severely limits the flight time of the hexacopter, and also
makes it harder to fly. How can weight be reduced?

\subsubsection{Battery}
\label{sec:battery}

The current setup uses separate batteries for the hexacopter (motors,
radios, etc) and for the payload. This was to reduce the likelihood
that a sudden spike in current draw (e.g. from climbing suddenly) from
causing a voltage drop that would cause the onboard computer to shut
down, or lead to corrupted data.

However, the payload battery lasts for upwards of an hour, whereas the
flight battery lasts for mere minutes. This is evidently not
optimal. How could this be addressed?

Can we use a single battery pack, keeping to computer and scanner
voltage stable by use of large capacitors? Probably not: once the
voltage drops exceed the millisecond time scale, the amount of
capacitance required becomes incredibly onerous.

Instead, it ought to be possible to better configure the batteries so
that the \emph{endurance} of the packs is roughly matched --- that is,
that the flight time roughly equals the length of time for which the
payload runs. An outline of how that might be achieved follows.

Firstly, the gimbal set could be connected to the main battery. Not
only is the gimbal the single biggest consumer of power, the firmware
can be configured to expect and compensate for fluctuating power.

This leaves just the scanner and the PC connected to the secondary
battery. On average these together use around 1.5A.  Say they are to
run for 30 minutes; that gives $1.5 \times 12 \times 0.5 = 9$Wh, or
$1.5 \times 0.5 \times 1000 = 750$mAh (assuming a 12V source). This
could be supplied with a lighter battery.

Unfortunately, LiPo batteries don't exactly hit 12V: a 3 cell battery
will supply 11.1V, and a 4 cell battery 14.8V. To minimise weight, it
would be preferable to use an 11.1V battery. If a boost converter is
used with 90\% efficiency:
\begin{equation}
  \label{eq:2}
  I_{\text{batt}} = 1.5 \times \frac{12}{11.1} \times \frac{1}{0.9} =
  1.80 \text{ A}
\end{equation}

At 1.80A, a battery would need 900mAh of capacity to last half an
hour, or if we want to ensure that we never drop below 25\% capacity:
\begin{equation}
  \label{eq:3}
  0.75c = 1.80 \times 0.5 \Rightarrow c = 1200 \text{ mAh}
\end{equation}

A 1200mAh 3 cell LiPo would weigh significantly less than the current
3300mAh, 4 cell battery (330g). (For instance, a 1800mAh battery weighs
in at 110g, and a 2200mAh battery weighs in at 163g.)

\subsubsection{PC selection}
\label{sec:electr-gener}

The previous section took as fixed the computer used in the
system. What if it wasn't? It may be possible to change the computer
for one which runs on 5V only, allowing a much greater voltage
variation to occur before problems are experienced. Two obvious
candidates are the Raspberry
Pi,\footnote{\url{http://www.raspberrypi.org/}} and the BeagleBone
Black.\footnote{\url{http://beagleboard.org/Products/BeagleBone+Black}}
Both of these boards run on 5V, consume vastly less power, and weigh
much less than the LP-170C board currently in use. However, they come
with their own set of complications:

\begin{description}
\item[Computational Power] The LP-170C has a 1.8GHz Atom CPU, whereas
  the BeagleBone has a 1GHz ARM Cortex A8, and the Raspberry Pi has a
  700MHz ARMv6 CPU.

  This obviously gives the LP-170C a significant (almost 2-fold)
  advantage in sheer computational grunt. Whether or not this will
  actually be an issue is unknown. Certainly with the current
  inefficient tree detection, the difference is likely to require a
  lower frame rate, but if the process can be done without conversion
  from polar to rectangular and the use of costly OpenCV operations,
  this advantage may fall away.
\item[Memory] The LP-170C has 4GB of memory, compared to 512MB on both
  the BeagleBone and the Raspberry Pi. While that's significantly
  less, it is very likely that most of the extra memory on the LP-170C is sitting
  idle. The board is not doing extensive graphics processing; it's not
  running a desktop environment; it's not doing particularly
  memory-intensive processing. (For instance, the map produced by the
  tree detector is presently 1200 by 1200 pixels, which given it's
  greyscale, equates to a mere 1.4 MB.)
\item[I/O] The LP-170C uses a CF card, the Raspberry Pi uses a SD
  card, and the BeagleBone has 4 GB of onboard flash.

  There are two relevant considerations: capacity and speed. While the
  BeagleBone has the most limited storage, it's still more than enough
  for a complete ROS distribution, especially if installed with care
  to avoid bringing in unnecessary items like RViz and a desktop
  environment.

  Of more pressing concern is the speed of the relevant storage
  technologies. The speed of writing a 768KB chunk has already proven
  to be problematic on the LP-170C (see Section~\ref{sec:psm-indoor}),
  and Raspberry Pis are notorious for poor IO performance. The
  BeagleBone's performance would need to be tested, but it's difficult
  to imagine it being significantly worse than either of the
  alternatives.
\item[Extensibility] All the solutions proposed support USB, which is
  by far the most likely avenue for extension peripherals. The LP also
  supports PCI-E mini-card, but it's difficult to see how this would
  be of benefit. The Raspberry Pi and the BeagleBone Black support
  GPIO with readily accessible sets of pins, which may be useful for
  integrating with the autopilot system.
\item[Graphics] The three have varying graphics hardware. However, the
  only use for this hardware is in setup and debugging: no graphics
  card processing is being contemplated. All the systems are perfectly
  suitable for this.
\end{description}

In conclusion, the Raspberry Pi is probably unwise, given its low
grunt and dismal IO, but serious consideration should be given to the
BeagleBone Black, especially if it becomes possible to process the
scan for trees using the polar method discussed in
Section~\ref{sec:future-direct-tree}, as that would largely obviate
the processing power issue.

If a BeagleBone Black could be deployed, it could safely be run on the
main power with an appropriate regulator. That would leave only the
laser scanner requiring a regulated 12V source. The scanner is also
probably less likely to be significantly affected by temporary
fluctuations in voltage, although this would need to be verified.
Ultimately this may enable the system to run on a single battery,
which would be a significant weight saving.

\subsubsection{Other ways of reducing weight}
\label{sec:other-ways-reducing}

As the landing gear was assembled largely as a prototype, there are
other potential weight savings that could be realised by a redesign
and rebuild.

With reference to Figure~\ref{fig:potential-hw-savings}, the following
aspects should be considered in future work:

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.7\textwidth]{figs/potential-hw-savings}
  \caption{Potential savings in hardware weight.\\\textbf{Yellow}: Gimbal top plate\\\textbf{Red}: Gimbal clamps attaching to top plate\\\textbf{Green}: Long power and USB cable from scanner.}
  \label{fig:potential-hw-savings}
\end{figure}

\begin{itemize}
\item Presently, the gimbal is mounted to the anti-vibration mount by
  means of cable ties attaching the mount to the top plate of the
  gimbal (yellow arrow). The top plate itself is attached to the
  central beam by means of two metal clamps (the front clamp is shown
  by the red arrow). Future work should investigate removing the top
  plate entirely, and attaching the beams to the anti-vibration mount
  either directly or though the existing clamps. This may require a
  redesign of the bottom plate of the anti-vibration mount, which has
  very unhelpfully positioned holes and cutouts.
\item There is a lot of excess cable bulk (green arrow), comprising
  both a USB cable and a combined power/serial cable for the
  scanner. Due to the prototype nature of the project, the excess
  cable was not cut out. However, if the project proceeds with this
  scanner, the cables should be shortened.
\end{itemize}

An additional design goal that should be considered when reducing
weight is to balance the hexacopter as a whole, which will increase
its efficiency and make it easier to fly. This will require a
more holistic design process than what was undertaken previously.

\subsection{Landing damage}
\label{sec:landing-damage}


A second concern is damage caused to the hardware by a hard landing on
the second flight trial.

Regrettably, no pictures were taken immediately after the landing, so
Figure~\ref{fig:damage} highlights areas of interest for discussion.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{figs/damage}
  \caption{Identification of areas of interest from crash.}
  \label{fig:damage}
\end{figure}

In the figure, the yellow circle identifies a gimbal joint that
`popped out', leading to a partial break along the red
line. Fortunately the break was not all the way through, so it was
possible to pop the joint back into place.

However, future work should address the obvious weakness this
reveals. Instead of merely having a plate on the base, there should
also be a plate at the top of the gimbal to provide the extra
rigidity. The frame will need to go around the scanner, and the design
will need to consider relocating the downwards reflecting mirror in
line with Section~\ref{sec:height-meas-setup}.

The base plate should also be redesigned in line with
Section~\ref{sec:mk-ii}: accidentally designing the screw holes to be
too small may well have been a contributing factor. When re-fabricating
the plate, it may also be worth considering a more durable material
than 3mm MDF.

\section{Future directions}
\label{sec:future-work}

Previous sections have considered future work in software and
hardware. This section considers future work in the system and project
more generally.

\subsection{Developing autonomy}
\label{sec:developing-autonomy}

The obvious future step for this project is to link the positioning
information into a control system. This ties in with the broader
context of forest exploration and the problem posed in the
introduction of locating people in a forest.

This will involve coordinating manual and automatic control,
especially for takeoff and landing, as well as having a manual
override in case of problems. However, ROS-MAVLink interaction is not
a new area, and so existing resources can be found to aid in this process.

\subsection{Other directions}
\label{sec:other-directions}

Following \cite{achtelik2009stereo}, it would be interesting to
integrate the laser scanner with some sort of camera.

\begin{itemize}
\item Adding a Kinect or a stereoscopic
camera (as in that paper) would open up a lot of interesting sensor
fusion opportunities. More practically, it would help to obviate the
fact that the laser scanner only provides a single plane, and would
help the hexacopter change altitude with confidence that it wasn't
going to hit something above or below it.
\item Even adding a monocular camera would be quite interesting. It
  would enable simple colour-based detection of foliage and other
  non-tree obstacles, which could be used quite fruitfully to prune
  the map of trees.
\end{itemize}

A particularly interesting direction that could be considered,
especially with reference to the problem of forest exploration posed
in the introduction, is the use of multiple cooperative
hexacopters.

\chapter{Conclusion}
\label{cha:conclusion}

\section{Acknowledgements}
\label{sec:acknowledgements}

\begin{itemize}
\item Jon Kim
\item Alex Martin
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Here begins the end matter

%\input appendix

\backmatter
\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,report}

\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "report"
%%% End: 



